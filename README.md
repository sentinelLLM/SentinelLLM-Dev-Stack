# SentinelLLM-Dev-Stack
# SentinelLLM: Real-Time Security Mesh for LLMs

## Overview
SentinelLLM protects conversational AI from prompt injection, hallucinations, tool misuse, and PII exposure. Built with modular Python microservices and a UI frontend.

## Modules
- ğŸ›¡ï¸ PromptShield â€“ Scans prompts for injection threats
- ğŸ”„ OutputSanitizer â€“ Redacts unsafe or sensitive output
- ğŸ§  HallucinationMeter â€“ Scores output confidence
- ğŸ§ª ShadowPrompt â€“ Simulates adversarial attacks
- ğŸ¤– AgentMesh â€“ Monitors and regulates agent behavior
- ğŸ’¬ SlackBot â€“ Sends threat alerts to team
- ğŸ–¥ Streamlit UI â€“ Interactive prompt testing

## Run Locally
