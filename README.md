# SentinelLLM-Dev-Stack
# SentinelLLM: Real-Time Security Mesh for LLMs

## Overview
SentinelLLM protects conversational AI from prompt injection, hallucinations, tool misuse, and PII exposure. Built with modular Python microservices and a UI frontend.

## Modules
- 🛡️ PromptShield – Scans prompts for injection threats
- 🔄 OutputSanitizer – Redacts unsafe or sensitive output
- 🧠 HallucinationMeter – Scores output confidence
- 🧪 ShadowPrompt – Simulates adversarial attacks
- 🤖 AgentMesh – Monitors and regulates agent behavior
- 💬 SlackBot – Sends threat alerts to team
- 🖥 Streamlit UI – Interactive prompt testing

## Run Locally
